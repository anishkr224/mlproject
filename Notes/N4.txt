Lec: 270

data_transformation.py

Data ingestion: we read dataset from a source, performed a train-test split, and saved the data inside an artifact folder.

Data transformation, involves feature engineering and data cleaning, such as converting categorical features into numerical features.

ColumnTransformer is used to build a pipeline where you can apply multiple transformations — like one-hot encoding for categorical features and standard scaling for numerical features — in a structured and efficient way.

SimpleImputer is a tool used for handling missing values in a dataset. Many machine learning algorithms don’t work well with missing data, so imputing (filling in) missing values is an essential preprocessing step.
Common strategies: mean, median, most_frequent, constant.

In utils.py, define a utility function save_object to save any Python object as a pickle file. It ensures the directory exists and uses dill to dump the object.

src\pipeline\train_pipeline.py file to check data_transformation.py is properly working or not.

(D:\mlproject\venv) D:\mlproject>python -m src.pipeline.train_pipeline

git add .
git status
git commit -m "Data Transformation"
git push -u origin main

Lec: 271

model_trainer.py

In utils.py, define a utility function evaluate_models to trains multiple models, evaluates them on train and test datasets using R2 score, and returns a dictionary of test scores for each model.

Update the train_pipeline.py file to check model_trainer.py is properly working or not.

python -m src.pipeline.train_pipeline

Go to .gitignore file; in # Environments remove .artifacts/

git add .
git status
git commit -m "Model Trainer"
git push -u origin main

Lec: 272

Model Hyperparameter Tuning Implementation

In model_trainer.py: Implemented hyperparameter tuning by integrating parameter grids for multiple machine learning algorithms.
In evaluate_models function: Utilized GridSearchCV from scikit-learn to perform cross-validated parameter search.

python -m src.pipeline.train_pipeline

git add .
git status
git commit -m "Hyperparameter tuning done"
git push -u origin main

Lec: 273

Building Prediction Pipeline

src\pipeline\predict_pipeline.py : To capture user input features and make predictions on input features.
In utils.py, define a utility function load_object to loads a Python object from the given file path using dill.

app.py : Flask based web application.
templates\index.html
templates\home.html

python app.py

http://127.0.0.1:5000/predictdata

git add .
git status
git commit -m "Prediction pipeline done"
git push -u origin main
